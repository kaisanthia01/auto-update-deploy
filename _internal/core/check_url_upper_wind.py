import requests
import sys
import re
import datetime
import json
from pathlib import Path
from bs4 import BeautifulSoup
import os
import logging

logger = logging.getLogger("CheckURLUpperWind")

# ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö UTF-8 ‡πÉ‡∏ô Windows Terminal
if sys.stdout:
    sys.stdout.reconfigure(encoding="utf-8")


class CheckURLUpperWind:
    def __init__(self, config_path=None):
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á config.json (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ default)"""
        script_dir = Path(__file__).resolve().parent  # ‚úÖ ‡πÉ‡∏ä‡πâ Path
        if config_path:
            self.config_file_path = Path(config_path)
        else:
            self.config_file_path = script_dir / "../data/json/config.json"

    def _load_config(self):
        if not self.config_file_path.exists():
            raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö config.json ‡∏ó‡∏µ‡πà: {self.config_file_path}")
        with self.config_file_path.open("r", encoding="utf-8") as f:
            return json.load(f)

    def _format_date(self, date_str, time_str):
        try:
            dt = datetime.datetime.strptime(date_str, "%Y-%m-%d")
            return {
                "day": dt.strftime("%d"),
                "month": dt.strftime("%b"),
                "year": dt.strftime("%y"),
                "ythai": str(dt.year + 543),
                "time": time_str[:2],
            }
        except Exception as e:
            raise ValueError(f"‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {e}")

    def _build_url(self, template_url, date_parts):
        for key, val in date_parts.items():
            template_url = template_url.replace(f"{{{key}}}", val)
        return template_url

    def _fetch_html(self, url):
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            response.encoding = "utf-8"
            return response.text
        except requests.RequestException as e:
            raise ConnectionError(f"‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

    def _extract_wind_text(self, html_text):
        """
        ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TTAA, TTBB, PPAA, PPBB ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å JSON
        ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÉ‡∏ä‡πâ station_id ‡πÄ‡∏õ‡πá‡∏ô key)
        """
        soup = BeautifulSoup(html_text, "html.parser")
        raw_text = soup.get_text(separator="\n", strip=True)

        if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ" in raw_text:
            return None, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"

        # ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
        cleaned = re.sub(r"\*-+\*?", "", raw_text)
        lines = [line.strip() for line in cleaned.splitlines() if line.strip()]
        full_text = " ".join(lines)
        full_text = re.sub(r"=", "=\n", full_text)
        full_text = re.sub(r"\*-*-*", "", full_text)
        lines = full_text.splitlines()

        temp_data = {}

        for line in lines:
            for code_type in ["TTAA", "TTBB", "PPAA", "PPBB"]:
                if code_type in line:
                    start = line.find(code_type)
                    end = line.find("=", start)
                    if end != -1:
                        raw = line[start : end + 1].strip()
                        parts = raw.split()
                        if len(parts) >= 3:
                            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: TTAA 74000 48455 ...
                            station = parts[2]  # ‡πÉ‡∏ä‡πâ‡∏£‡∏´‡∏±‡∏™ WMO station

                            # üîΩ ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
                            if not station.startswith(
                                (
                                    "31",
                                    "32",
                                    "36",
                                    "38",
                                    "40",
                                    "41",
                                    "42",
                                    "43",
                                    "44",
                                    "45",
                                    "46",
                                    "47",
                                    "48",
                                    "51",
                                    "52",
                                    "53",
                                    "54",
                                    "55",
                                    "56",
                                    "57",
                                    "58",
                                    "59",
                                    "91",
                                    "92",
                                    "94",
                                    "96",
                                    "97",
                                    "98",
                                )
                            ):
                                continue

                            # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô temp_data (‡∏à‡∏∞ override ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ã‡πâ‡∏≥)
                            raw = re.sub(r"=", "", " ".join(raw.split()))
                            if station not in temp_data:
                                temp_data[station] = {}
                            temp_data[station][code_type] = raw
                        else:
                            continue

        # ‚úÖ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏° station_id
        if not temp_data:
            return None, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™ TTAA/PPAA/PPBB ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ"

        data_by_station = {
            station: temp_data[station] for station in sorted(temp_data.keys())
        }

        return (
            data_by_station,
            f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(data_by_station)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏à‡∏≤‡∏Å Upper-Air Report",
        )

    def _save_to_json(self, data_by_station: dict, date: str):
        """
        ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏Ñ‡∏£‡∏ö TTAA/TTBB/PPAA/PPBB
        """
        script_dir = Path(__file__).resolve().parent
        output_path = script_dir / "../data/json/synop_url_upperwind.json"
        output_path = output_path.resolve()

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        output_path.parent.mkdir(parents=True, exist_ok=True)
        logger.info(f"‚úÖ Directory OK: {output_path.parent}")

        try:
            all_data = {date: {}}
            for station, report_dict in data_by_station.items():
                all_data[date][station] = {
                    code_type: report_dict.get(code_type, "NIL")
                    for code_type in ["TTAA", "TTBB", "PPAA", "PPBB"]
                }

            with output_path.open("w", encoding="utf-8") as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡πâ‡∏ß: {output_path}")

        except Exception as e:
            logger.error(f"‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
            raise IOError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON: {e}")

    def urlGetContent(self, time: str, date: str, html_text: str = None):
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏¢‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
        """
        try:
            config = self._load_config()
            url_template = config["settings"]["url_wind"]
            date_parts = self._format_date(date, time)
            url = self._build_url(url_template, date_parts)
            logger.info(f"‚úÖ URL: {url}")

            if html_text is not None:
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ HTML ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ HTML ‡∏ô‡∏±‡πâ‡∏ô‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡πÉ‡∏´‡∏°‡πà
                html = html_text
            else:
                html = self._fetch_html(url)

            result, status = self._extract_wind_text(html)
            if not result:
                logger.warning("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TTAA/PPAA/PPBB ‡πÉ‡∏ô HTML")
                return "NIL", status

            self._save_to_json(result, date)
            return result, f"{status} ({len(result)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ)"
        except Exception as e:
            logger.error(f"‚ùå Exception in urlGetContent: {e}")
            return "NIL", f"ERROR: {e}"


# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 2025-03-25 ‡πÄ‡∏ß‡∏•‡∏≤ 00 UTC
# checker = CheckURLUpperWind()
# result, status = checker.urlGetContent(time="00", date="2025-03-28")

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# print(status)
# if result != "NIL":
#    for station, report in result.items():
#        print(f"\nüìç ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ: {station}")
#        for code_type, text in report.items():
#            print(f"  ‚û§ {code_type}: {text}")
